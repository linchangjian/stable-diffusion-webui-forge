#!/usr/bin/env python3
"""
å¢å¼ºçš„å¯åŠ¨è„šæœ¬ï¼ŒåŒ…å«è¯¦ç»†çš„ç»„ä»¶çŠ¶æ€æ—¥å¿—
ç‰¹åˆ«ç›‘æ§ xformers çš„è¿è¡ŒçŠ¶æ€
"""

import os
import sys
import time
import logging
from datetime import datetime

# è®¾ç½®æ—¥å¿—
def setup_logging():
    """è®¾ç½®è¯¦ç»†çš„æ—¥å¿—è®°å½•"""
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"startup_{timestamp}.log")
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger(__name__)

def check_torch_environment():
    """æ£€æŸ¥ PyTorch ç¯å¢ƒ"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 60)
    logger.info("æ£€æŸ¥ PyTorch ç¯å¢ƒ...")
    
    try:
        import torch
        logger.info(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
        logger.info(f"âœ… CUDA å¯ç”¨: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            logger.info(f"âœ… CUDA ç‰ˆæœ¬: {torch.version.cuda}")
            logger.info(f"âœ… GPU æ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                logger.info(f"âœ… GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
        else:
            logger.warning("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU")
            
    except Exception as e:
        logger.error(f"âŒ PyTorch æ£€æŸ¥å¤±è´¥: {e}")
        return False
    
    return True

def check_torchvision():
    """æ£€æŸ¥ TorchVision"""
    logger = logging.getLogger(__name__)
    logger.info("æ£€æŸ¥ TorchVision...")
    
    try:
        import torchvision
        logger.info(f"âœ… TorchVision ç‰ˆæœ¬: {torchvision.__version__}")
        return True
    except Exception as e:
        logger.error(f"âŒ TorchVision æ£€æŸ¥å¤±è´¥: {e}")
        return False

def check_xformers():
    """æ£€æŸ¥ xformers çŠ¶æ€"""
    logger = logging.getLogger(__name__)
    logger.info("æ£€æŸ¥ xformers çŠ¶æ€...")
    
    try:
        import xformers
        logger.info(f"âœ… xformers ç‰ˆæœ¬: {xformers.__version__}")
        
        # æ£€æŸ¥ xformers æ˜¯å¦å¯ç”¨
        if hasattr(xformers, '_has_cpp_library'):
            cpp_available = xformers._has_cpp_library
            logger.info(f"âœ… xformers C++ åº“: {'å¯ç”¨' if cpp_available else 'ä¸å¯ç”¨'}")
        else:
            logger.warning("âš ï¸  æ— æ³•æ£€æŸ¥ xformers C++ åº“çŠ¶æ€")
        
        # æµ‹è¯• xformers åŠŸèƒ½
        try:
            import torch
            if torch.cuda.is_available():
                # åˆ›å»ºæµ‹è¯•å¼ é‡
                device = torch.device('cuda')
                q = torch.randn(1, 8, 64, 64, device=device)
                k = torch.randn(1, 8, 64, 64, device=device)
                v = torch.randn(1, 8, 64, 64, device=device)
                
                # æµ‹è¯• xformers æ³¨æ„åŠ›
                from xformers.ops import memory_efficient_attention
                output = memory_efficient_attention(q, k, v)
                logger.info("âœ… xformers æ³¨æ„åŠ›æœºåˆ¶æµ‹è¯•æˆåŠŸ")
                
                # æ¸…ç†å†…å­˜
                del q, k, v, output
                torch.cuda.empty_cache()
                
        except Exception as e:
            logger.warning(f"âš ï¸  xformers åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ xformers æ£€æŸ¥å¤±è´¥: {e}")
        return False

def check_other_dependencies():
    """æ£€æŸ¥å…¶ä»–é‡è¦ä¾èµ–"""
    logger = logging.getLogger(__name__)
    logger.info("æ£€æŸ¥å…¶ä»–ä¾èµ–...")
    
    dependencies = [
        ('numpy', 'NumPy'),
        ('PIL', 'Pillow'),
        ('transformers', 'Transformers'),
        ('accelerate', 'Accelerate'),
        ('diffusers', 'Diffusers'),
    ]
    
    for module, name in dependencies:
        try:
            __import__(module)
            logger.info(f"âœ… {name}: å·²å®‰è£…")
        except ImportError:
            logger.warning(f"âš ï¸  {name}: æœªå®‰è£…")

def main():
    """ä¸»å‡½æ•°"""
    logger = setup_logging()
    
    logger.info("ğŸš€ å¯åŠ¨ Stable Diffusion WebUI Forge")
    logger.info(f"ğŸ“… å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"ğŸ Python ç‰ˆæœ¬: {sys.version}")
    logger.info(f"ğŸ“ å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    logger.info("æ£€æŸ¥ç¯å¢ƒå˜é‡...")
    cuda_visible_devices = os.environ.get('CUDA_VISIBLE_DEVICES', 'æœªè®¾ç½®')
    logger.info(f"CUDA_VISIBLE_DEVICES: {cuda_visible_devices}")
    
    # æ£€æŸ¥å„ä¸ªç»„ä»¶
    components_ok = True
    
    if not check_torch_environment():
        components_ok = False
    
    if not check_torchvision():
        components_ok = False
    
    if not check_xformers():
        components_ok = False
    
    check_other_dependencies()
    
    if not components_ok:
        logger.error("âŒ å…³é”®ç»„ä»¶æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return False
    
    logger.info("=" * 60)
    logger.info("âœ… æ‰€æœ‰ç»„ä»¶æ£€æŸ¥å®Œæˆï¼Œå¯åŠ¨ WebUI...")
    logger.info("=" * 60)
    
    # å¯åŠ¨ WebUI
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæ·»åŠ  --disable-gpu-warning å‚æ•°
        current_args = os.environ.get('COMMANDLINE_ARGS', '')
        if '--disable-gpu-warning' not in current_args:
            os.environ['COMMANDLINE_ARGS'] = current_args + ' --disable-gpu-warning'
            logger.info("âœ… å·²æ·»åŠ  --disable-gpu-warning å‚æ•°")
        
        # å¯¼å…¥å¹¶å¯åŠ¨åŸå§‹ webui
        from webui import main_thread, webui
        
        # å¯åŠ¨ WebUI
        webui()
        
        # è¿è¡Œä¸»å¾ªç¯
        main_thread.loop()
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)